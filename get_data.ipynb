{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "async def async_map_get(urls):\n",
    "    resp = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        responses = [session.get(url) for url in urls]\n",
    "        for chunk in chunks(responses, 95):\n",
    "            resp.extend(await asyncio.gather(*chunk))\n",
    "            await asyncio.sleep(60*5 + 10)\n",
    "    return [await r.json() for r in resp]\n",
    "\n",
    "def paper_url(paper_id, fields):\n",
    "    return f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}?fields={','.join(fields)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['bf79c966b293dbc5551de9785a696c099dff355b',\n",
       "       '86b1a0e7f9f778ba6e5a6c547d70dfebfa45ed95',\n",
       "       '0228810a988f6b8f06337e14f564e2fd3f6e1056',\n",
       "       '60e28c7da56eb61dd8ddb710a6f079ef02668014',\n",
       "       'c4ec5dc7d68d858e141113feca9921c632b3b2d5',\n",
       "       '56703e0ccba03378962f5006f299cd98d48198f9',\n",
       "       '3cb54f04765c19e7e0580196c29c64e49f63a744',\n",
       "       'd3f788ee95e16dac7a2e4d65aa095199bbc3439f',\n",
       "       '5194b668c67aa83c037e71599a087f63c98eb713',\n",
       "       '9c7f4412b8f0310a91334aed79b8553b2ad70908',\n",
       "       'a39398f68ae7e042f2ef5009e31b4e6a20fd5736',\n",
       "       '6989e13df80edfc6e638e8d8502cb0739d494ca6',\n",
       "       '89b22325e7d72d11c5bad8f3893d45d0e184fa9b',\n",
       "       '6965c8e2dcd6ecf2a5f3f9320de5fced37391e42',\n",
       "       'b6b743de242a2987b3ed0349d90971fdf7ed2faf',\n",
       "       '05e5a4c51b6df1ffa8d9b76f88ad0d2c92f4627a',\n",
       "       '5c89852b90a1e9e506d237749c745bf42ac0f737',\n",
       "       '0f910174d2e19101ca8f008909006e79416821fd',\n",
       "       'd26a48aff2abc3460c1018d5b410766f698d696c',\n",
       "       '04f67e55a636b9053ddc30f55def0ee3fc1c8e2b',\n",
       "       'b87c0cf95208caacb025bf87d9ba451a87aacaca',\n",
       "       '33dcf9b0989826a350bf58145e179e99f8c21b36',\n",
       "       '66f44806cd46a27f02ceb74bdfd9ad6e77e044ca',\n",
       "       'b96ce653b41f9850a88452aaa959eda875c2a482',\n",
       "       '3b12ddce41b574c27fce7fe0da51c653564f7d45',\n",
       "       '7d58496aedad3ab8e035606a450a2d0142c2fd79',\n",
       "       'ef944614bfc82b1dedfea19ff249a97ceea5ad90',\n",
       "       '0a8149fb5aa8a5684e7d530c264451a5cb9250f5',\n",
       "       '15c10b24ef645d83ff4059affd86945c33e00328',\n",
       "       'e767ea3f3875f096a70bbdac4847436a5e30800e'], dtype='<U40')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial papers\n",
    "n_papers = 30\n",
    "offset = 1040\n",
    "url = f\"https://api.semanticscholar.org/graph/v1/paper/search?query=machine+learning&limit={n_papers}&offset={offset}&fields=paperId,title\"\n",
    "response = get(url)\n",
    "print(response)\n",
    "initial_papers = json.loads(response.content)\n",
    "ids = np.array([paper[\"paperId\"] for paper in initial_papers[\"data\"]])\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [paper_url(id, [\"title\", \"references\", \"embedding\"]) for id in ids]\n",
    "initial_paper_data = [get(url).json() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n",
      "1288\n"
     ]
    }
   ],
   "source": [
    "citations = []\n",
    "all_ids = set()\n",
    "for paper in initial_paper_data:\n",
    "    all_ids.add(paper[\"paperId\"])\n",
    "    for target in paper[\"references\"]:\n",
    "        if target[\"paperId\"]:\n",
    "            citations.append([\n",
    "                paper[\"paperId\"],\n",
    "                target[\"paperId\"],\n",
    "            ])\n",
    "            all_ids.add(target[\"paperId\"])\n",
    "citations = pd.DataFrame(citations, columns=[\"source\", \"target\"])\n",
    "print(len(all_ids))\n",
    "citations.to_csv(\"citations.csv\", index=False)\n",
    "print(len(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [paper_url(id, [\"title\", \"embedding\"]) for id in all_ids - {None}]\n",
    "paper_data = await async_map_get(urls)\n",
    "paper_data = pd.DataFrame(paper_data)\n",
    "paper_data[\"embedding\"] = paper_data[\"embedding\"].apply(lambda x: x[\"vector\"])\n",
    "paper_data.to_csv(\"paper_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
